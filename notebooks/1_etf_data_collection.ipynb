{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: ETF Data Collection\n",
    "\n",
    "## This Chapter\n",
    "We build and maintain our ETF database:\n",
    "1. Connect to DEGIRO\n",
    "2. Apply base filter criteria (Irish domicile, accumulating, EUR)\n",
    "3. Fetch price data for each ETF from JustETF\n",
    "4. Save everything to SQLite database for easy updates\n",
    "\n",
    "**Note**: We collect broadly here (no fund size or history filters). More restrictive filters are applied later when using the data for analysis.\n",
    "\n",
    "## Output\n",
    "- `data/etf_database.db` - SQLite database containing:\n",
    "  - `etfs` table: ETF metadata (name, TER, fund size, etc.)\n",
    "  - `prices` table: Historical price data\n",
    "\n",
    "## Monthly Updates\n",
    "After initial setup, run Section 1.5 to update prices for existing ETFs and add any new ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Setup & Connect to DEGIRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import justetf_scraping\n",
    "\n",
    "# Add current directory to path\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEGIRO: Connecting...\n",
      "  ACTION REQUIRED:\n",
      "  Open the DEGIRO app on your phone\n",
      "  Tap 'Yes' to approve this login\n",
      "  Waiting for approval...\n",
      "\n",
      "Connected successfully!\n",
      "================================================================================\n",
      "Connected to DEGIRO\n"
     ]
    }
   ],
   "source": [
    "# Connect to DEGIRO\n",
    "from degiro_client import get_client\n",
    "\n",
    "client = get_client()\n",
    "api = client.api\n",
    "\n",
    "print(\"Connected to DEGIRO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new empty database\n"
     ]
    }
   ],
   "source": [
    "# Initialize database (creates if not exists, connects if exists)\n",
    "from etf_database import ETFDatabase\n",
    "\n",
    "db = ETFDatabase(\"data/etf_database.db\")\n",
    "\n",
    "stats = db.get_stats()\n",
    "if stats['total_etfs'] > 0:\n",
    "    print(f\"Connected to existing database: {stats['total_etfs']} ETFs, {stats['total_price_records']:,} prices\")\n",
    "else:\n",
    "    print(\"Created new empty database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Fetch ETF Universe from DEGIRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etf_fetcher import ETFFetcher, ETFFilter\n",
    "\n",
    "# Initialize fetcher (uses existing DEGIRO connection)\n",
    "fetcher = ETFFetcher(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filter criteria\n",
    "satellite_filter = ETFFilter(\n",
    "    isin_prefix=\"IE00\",           # Irish domiciled (tax efficient)\n",
    "    distribution=\"Accumulating\",  # Reinvest dividends\n",
    "    currency=\"EUR\",               # Currency in Euros\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching DEGIRO ETF catalog...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Fetching: 100%|███████████████████████| 7742/7742 [00:43<00:00, 174.37 ETFs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 7565 ETFs on DEGIRO\n",
      "Loading JustETF data...\n",
      "  Loaded 3926 ETFs from JustETF\n",
      "\n",
      "Filtering 2806 ETFs...\n",
      "  Domicile (IE00): 1709 ETFs\n",
      "  JustETF match: 1636 ETFs\n",
      "  Distribution (Accumulating): 1104 ETFs\n",
      "  Currency (EUR): 937 ETFs\n",
      "  Fetching data history from JustETF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Checking history: 100%|█████████████████████| 902/902 [08:39<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Deduplicated: 902 ETFs (by longest history)\n",
      "\n",
      "Result: 902 ETFs\n",
      "\n",
      "Found 902 ETFs matching criteria\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetch ETFs matching our criteria\n",
    "df_universe = fetcher.fetch(satellite_filter)\n",
    "print(f\"\\nFound {len(df_universe)} ETFs matching criteria\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 30 leveraged ETFs\n",
      "Remaining ETFs: 872\n"
     ]
    }
   ],
   "source": [
    "# Filter out leveraged ETFs\n",
    "leverage_keywords = ['leveraged', 'leverage', '2x', '3x', 'ultra', 'double', 'triple',\n",
    "                     'levered', 'geared', 'x2', 'x3', '200%', '300%']\n",
    "\n",
    "initial_count = len(df_universe)\n",
    "df_universe = df_universe[\n",
    "    ~df_universe['Name'].str.lower().str.contains('|'.join(leverage_keywords), na=False)\n",
    "]\n",
    "\n",
    "filtered_count = initial_count - len(df_universe)\n",
    "print(f\"Filtered out {filtered_count} leveraged ETFs\")\n",
    "print(f\"Remaining ETFs: {len(df_universe)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Add ETFs to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding ETFs to database: 100%|██████████| 872/872 [00:14<00:00, 59.41it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Added 872 new ETFs\n",
      "Updated 0 existing ETFs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Add all ETFs to database\n",
    "# Helper to convert pandas NA to None for SQLite\n",
    "def to_python(val):\n",
    "    \"\"\"Convert pandas NA/NaN to Python None.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    return val\n",
    "\n",
    "added_count = 0\n",
    "updated_count = 0\n",
    "\n",
    "for _, row in tqdm(df_universe.iterrows(), total=len(df_universe), desc=\"Adding ETFs to database\"):\n",
    "    is_new = db.add_etf(\n",
    "        isin=row['ISIN'],\n",
    "        name=row['Name'],\n",
    "        vwd_id=str(row.get('vwdId', '')),\n",
    "        exchange=to_python(row.get('exchange')),\n",
    "        currency=to_python(row.get('currency')),\n",
    "        ter=to_python(row.get('TER')),\n",
    "        fund_size=to_python(row.get('fund_size')),\n",
    "        distribution='Accumulating',\n",
    "        months_of_data=to_python(row.get('months_of_data'))\n",
    "    )\n",
    "    if is_new:\n",
    "        added_count += 1\n",
    "    else:\n",
    "        updated_count += 1\n",
    "\n",
    "print(f\"\\nAdded {added_count} new ETFs\")\n",
    "print(f\"Updated {updated_count} existing ETFs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Fetch and Store Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching price data for 872 ETFs...\n",
      "(This may take several minutes)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching prices: 100%|██████████| 872/872 [09:52<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully fetched prices for 843/872 ETFs\n",
      "Failed to fetch prices for 29 ETFs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetch price data from JustETF and store in database\n",
    "# This fetches FULL history for each ETF and validates overlap before replacing\n",
    "\n",
    "isins = df_universe['ISIN'].tolist()\n",
    "success_count = 0\n",
    "fail_count = 0\n",
    "validation_warnings = []\n",
    "\n",
    "print(f\"Fetching price data for {len(isins)} ETFs...\")\n",
    "print(\"(This may take several minutes)\\n\")\n",
    "\n",
    "for isin in tqdm(isins, desc=\"Fetching prices\"):\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            prices = justetf_scraping.load_chart(isin, currency='EUR')\n",
    "        \n",
    "        if prices is not None and len(prices) > 0:\n",
    "            # Convert to Series if DataFrame\n",
    "            if isinstance(prices, pd.DataFrame):\n",
    "                prices = prices.iloc[:, 0]\n",
    "            \n",
    "            # Validate new prices against existing (if any)\n",
    "            validation = db.validate_new_prices(isin, prices)\n",
    "            \n",
    "            if not validation['valid']:\n",
    "                # Price mismatch in overlap period - warn but continue\n",
    "                validation_warnings.append({\n",
    "                    'isin': isin,\n",
    "                    'mismatches': len(validation['mismatches']),\n",
    "                    'overlap_days': validation['overlap_days'],\n",
    "                    'sample': validation['mismatches'][:3]  # First 3 mismatches\n",
    "                })\n",
    "            \n",
    "            # Store in database (replace=True for full refresh)\n",
    "            records_added = db.update_prices(isin, prices, replace=True)\n",
    "            if records_added > 0:\n",
    "                success_count += 1\n",
    "            else:\n",
    "                fail_count += 1\n",
    "        else:\n",
    "            fail_count += 1\n",
    "    except Exception as e:\n",
    "        fail_count += 1\n",
    "    \n",
    "    # Rate limiting for JustETF\n",
    "    time.sleep(0.3)\n",
    "\n",
    "print(f\"\\nSuccessfully fetched prices for {success_count}/{len(isins)} ETFs\")\n",
    "if fail_count > 0:\n",
    "    print(f\"Failed to fetch prices for {fail_count} ETFs\")\n",
    "\n",
    "# Show validation warnings (if any)\n",
    "if validation_warnings:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"WARNING: {len(validation_warnings)} ETFs had price mismatches in overlap period\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(\"(Historical prices may have been corrected by the data source)\\n\")\n",
    "    \n",
    "    for warn in validation_warnings[:10]:  # Show first 10\n",
    "        print(f\"  {warn['isin']}: {warn['mismatches']} mismatches in {warn['overlap_days']} overlap days\")\n",
    "        if warn['sample']:\n",
    "            for date, old_p, new_p in warn['sample'][:2]:\n",
    "                pct_diff = (new_p - old_p) / old_p * 100\n",
    "                print(f\"    - {date.strftime('%Y-%m-%d')}: {old_p:.2f} -> {new_p:.2f} ({pct_diff:+.2f}%)\")\n",
    "    \n",
    "    if len(validation_warnings) > 10:\n",
    "        print(f\"\\n  ... and {len(validation_warnings) - 10} more ETFs with warnings\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATA QUALITY CHECK\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking data quality: 100%|██████████| 872/872 [00:04<00:00, 187.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Status             Count\n",
      "-------------------------\n",
      "Good ETFs            818\n",
      "With Issues           54\n",
      "Total                872\n",
      "\n",
      "======================================================================\n",
      "ETFs WITH DATA QUALITY ISSUES:\n",
      "======================================================================\n",
      "ISIN            Name                                     Issue                         \n",
      "-------------------------------------------------------------------------------------\n",
      "IE00000EF730    iShares Europe Equity Enhanced Active UC NO DATA                       \n",
      "IE00002ZKAP0    Xtrackers Europe Equity Enhanced Active  NO DATA                       \n",
      "IE00004PGEY9    JPM Eurozone Research Enhanced Index Equ NO DATA                       \n",
      "IE00004S2680    Vanguard EUR Eurozone Government 1-3 Yea NO DATA                       \n",
      "IE0000902GT6    WisdomTree Megatrends UCITS ETF - USD Ac NO DATA                       \n",
      "IE0000EAPBT6    JPMorgan US Equity Premium Income Active NO DATA                       \n",
      "IE0000FCGYF9    Invesco S&P China A MidCap 500 Swap UCIT NO DATA                       \n",
      "IE0000H445G8    VanEck New China ESG UCITS ETF           NO DATA                       \n",
      "IE0000P0RPE6    iShares World Equity High Income UCITS E NO DATA                       \n",
      "IE0000U24AJ9    Amundi MSCI USA SRI Climate Net Zero Amb NO DATA                       \n",
      "IE0000UJ3480    iShares iBond Dec 2028 Term $ Corp UCITS NO DATA                       \n",
      "IE000HGH8PV2    Global X S&P 500 Annual Tail Hedge UCITS NO DATA                       \n",
      "IE000HPBRE54    Goldman Sachs Paris-Aligned Climate Worl NO DATA                       \n",
      "IE000HT7E0B1    Xtrackers Nordic Net Zero Pathway Paris  NO DATA                       \n",
      "IE000HYFO765    Goldman Sachs Alpha Enhanced US Equity A NO DATA                       \n",
      "IE000I1D7D10    iShares iBonds Dec 2027 Term $ Corp UCIT NO DATA                       \n",
      "IE000I25S1V5    Invesco Bulletshares 2030 EUR Corporate  NO DATA                       \n",
      "IE000I7E6HL0    HANetf Future of European Defence UCITS  NO DATA                       \n",
      "IE000I8IKC59    Invesco MSCI Japan ESG Clim Par Al UCITS NO DATA                       \n",
      "IE000I8KRLL9    iShares MSCI Global Semiconductors UCITS NO DATA                       \n",
      "IE000IAPH329    AXA IM US High Yield Opportunities UCITS NO DATA                       \n",
      "IE000IAXNM41    iShares Europe Defence UCITS ETF EUR (Ac NO DATA                       \n",
      "IE000IISJT64    SPDR S&P Developed Quality Aristocrats U NO DATA                       \n",
      "IE000IM4K4K2    Franklin Metaverse UCITS ETF             NO DATA                       \n",
      "IE000IP0UC52    Amundi MSCI USA ESG Leaders UCITS ETF Ac NO DATA                       \n",
      "IE000IQQEL77    Sprott Copper Miners ESG Screened UCITS  NO DATA                       \n",
      "IE000IUNJSL2    SPDR Bloomberg 0-3 Year Euro Corporate B NO DATA                       \n",
      "IE000IZO7033    iShares Green Bond UCITS ETF EUR Acc     NO DATA                       \n",
      "IE000J0LN0R5    Amundi S&P Global Energy Carbon Reduced  NO DATA                       \n",
      "IE000UWJUW87    HANActCATBETFP                           Short history (10 days)       \n",
      "IE000W8WMSL2    WisdomTree Quantum Computing UCITS ETF U Short history (107 days)      \n",
      "IE00BD4TXW66    UBS Core S&P 500 UCITS ETF USD acc       Short history (130 days)      \n",
      "IE000C7EUDG1    Future of Defence Indo-Pac ex-China UCIT Short history (136 days)      \n",
      "IE000ZAJ6XQ2    JPM India Research Enhanced Index Equity Short history (137 days)      \n",
      "IE000YELA4E3    L&G S&P 100 Equal Weight UCITS ETF USD A Short history (151 days)      \n",
      "IE000Q8F0M81    Trackers First Trust Nasdaq Clean Edge G Short history (164 days)      \n",
      "IE000YIQZ0H6    First Trust Bloomberg Artificial Intelli Short history (164 days)      \n",
      "IE000E6TPCH9    Invesco S&P 500 Quality UCITS ETF Acc    Short history (173 days)      \n",
      "IE0008GRJRO8    SPDR® S&P Europe Defense Vision UCITS ET Short history (193 days)      \n",
      "IE0007Y8Y157    VanEck Quantum Computing UCITS ETF Acc   Short history (206 days)      \n",
      "IE000WRQ9RR1    Global X Europe Focused Defence Tech UCI Short history (207 days)      \n",
      "IE0002PGSLZ5    Xtrackers US Equity Enhanced Active UCIT Short history (211 days)      \n",
      "IE00094GSCQ4    Xtrackers World Equity Enhanced Active U Short history (211 days)      \n",
      "IE000ZUTO1I5    Goldman Sachs Alpha Enhanced Japan Equit Short history (213 days)      \n",
      "IE000RITWOD4    Goldman Sachs Alpha Enhanced Europe Equi Short history (220 days)      \n",
      "IE000UFAX9L6    Goldman Sachs Alpha Enhanced World Equit Short history (220 days)      \n",
      "IE000O6GI299    Goldman Sachs EUR Investment Grade Corpo Short history (226 days)      \n",
      "IE00041H4WT9    HANetf Future of Defence Screened UCITS  Short history (32 days)       \n",
      "IE000YPOHA39    Invesco EUR Overnight Return Swap UCITS  Short history (45 days)       \n",
      "IE000AON7ET1    ARK Space & Defence Innovation UCITS ETF Short history (46 days)       \n",
      "IE0003HV7CS6    Shares iBonds Dec 2028 Term € Corp Cross Short history (64 days)       \n",
      "IE000O1FWAW6    iShares iBonds Dec 2035 Term € Corp UCIT Short history (64 days)       \n",
      "IE000UJSC3C9    iShares iBonds Dec 2029 Term € Corp Cros Short history (64 days)       \n",
      "IE000OV4XWA3    WisdomTree Eurozone Efficient Core UCITS Short history (74 days)       \n",
      "\n",
      "Issue Summary:\n",
      "  - No data: 29 ETFs\n",
      "\n",
      "======================================================================\n",
      "Data quality check complete. 818/872 ETFs have good data.\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Check\n",
    "# Verify price data completeness and identify any gaps\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_isins = db.list_isins()\n",
    "quality_issues = []\n",
    "good_etfs = 0\n",
    "\n",
    "for isin in tqdm(all_isins, desc=\"Checking data quality\"):\n",
    "    prices = db.load_prices(isin)\n",
    "    etf_info = db.get_etf(isin)\n",
    "    name = etf_info['name'][:40] if etf_info else isin\n",
    "    \n",
    "    if len(prices) == 0:\n",
    "        quality_issues.append((isin, name, \"NO DATA\", 0, None))\n",
    "        continue\n",
    "    \n",
    "    # Calculate metrics\n",
    "    date_range = (prices.index.max() - prices.index.min()).days\n",
    "    expected_trading_days = date_range * 5 / 7  # Rough estimate\n",
    "    actual_days = len(prices)\n",
    "    coverage = actual_days / expected_trading_days if expected_trading_days > 0 else 0\n",
    "    \n",
    "    # Check for gaps (more than 5 consecutive missing days)\n",
    "    date_diff = prices.index.to_series().diff().dt.days\n",
    "    max_gap = date_diff.max() if len(date_diff) > 0 else 0\n",
    "    \n",
    "    # Check for stale data (last update more than 7 days ago)\n",
    "    days_since_update = (pd.Timestamp.now() - prices.index.max()).days\n",
    "    \n",
    "    # Flag issues\n",
    "    issues = []\n",
    "    if coverage < 0.85:\n",
    "        issues.append(f\"Low coverage ({coverage:.0%})\")\n",
    "    if max_gap > 10:\n",
    "        issues.append(f\"Gap of {max_gap} days\")\n",
    "    if days_since_update > 7:\n",
    "        issues.append(f\"Stale ({days_since_update}d old)\")\n",
    "    if len(prices) < 252:  # Less than 1 year of data\n",
    "        issues.append(f\"Short history ({len(prices)} days)\")\n",
    "    \n",
    "    if issues:\n",
    "        quality_issues.append((isin, name, \", \".join(issues), len(prices), prices.index.max()))\n",
    "    else:\n",
    "        good_etfs += 1\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'Status':<15} {'Count':>8}\")\n",
    "print(\"-\"*25)\n",
    "print(f\"{'Good ETFs':<15} {good_etfs:>8}\")\n",
    "print(f\"{'With Issues':<15} {len(quality_issues):>8}\")\n",
    "print(f\"{'Total':<15} {len(all_isins):>8}\")\n",
    "\n",
    "# Show issues if any\n",
    "if quality_issues:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"ETFs WITH DATA QUALITY ISSUES:\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"{'ISIN':<15} {'Name':<40} {'Issue':<30}\")\n",
    "    print(\"-\"*85)\n",
    "    for isin, name, issue, days, last_date in sorted(quality_issues, key=lambda x: x[2]):\n",
    "        print(f\"{isin:<15} {name:<40} {issue:<30}\")\n",
    "    \n",
    "    # Categorize issues\n",
    "    no_data = [q for q in quality_issues if \"NO DATA\" in q[2]]\n",
    "    stale = [q for q in quality_issues if \"Stale\" in q[2]]\n",
    "    gaps = [q for q in quality_issues if \"Gap\" in q[2]]\n",
    "    \n",
    "    print(f\"\\nIssue Summary:\")\n",
    "    if no_data:\n",
    "        print(f\"  - No data: {len(no_data)} ETFs\")\n",
    "    if stale:\n",
    "        print(f\"  - Stale data: {len(stale)} ETFs\")\n",
    "    if gaps:\n",
    "        print(f\"  - Large gaps: {len(gaps)} ETFs\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Data quality check complete. {good_etfs}/{len(all_isins)} ETFs have good data.\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying 29 ETFs with no data...\n",
      "(Using longer delay to avoid rate limiting)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying: 100%|██████████| 29/29 [00:38<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retry results: 29 succeeded, 0 still failed\n",
      "ETFs with prices: 872/872\n"
     ]
    }
   ],
   "source": [
    "# Retry fetching prices for ETFs with no data\n",
    "# (Rate limiting may have caused failures during initial fetch)\n",
    "\n",
    "# Find ETFs with no price data\n",
    "no_data_isins = [isin for isin, _, issue, _, _ in quality_issues if \"NO DATA\" in issue]\n",
    "\n",
    "if no_data_isins:\n",
    "    print(f\"Retrying {len(no_data_isins)} ETFs with no data...\")\n",
    "    print(\"(Using longer delay to avoid rate limiting)\\n\")\n",
    "    \n",
    "    retry_success = 0\n",
    "    retry_fail = 0\n",
    "    \n",
    "    for isin in tqdm(no_data_isins, desc=\"Retrying\"):\n",
    "        try:\n",
    "            time.sleep(1.0)  # Longer delay for retry\n",
    "            \n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                prices = justetf_scraping.load_chart(isin, currency='EUR')\n",
    "            \n",
    "            if prices is not None and len(prices) > 0:\n",
    "                if isinstance(prices, pd.DataFrame):\n",
    "                    prices = prices.iloc[:, 0]\n",
    "                \n",
    "                records_added = db.update_prices(isin, prices, replace=True)\n",
    "                if records_added > 0:\n",
    "                    retry_success += 1\n",
    "                else:\n",
    "                    retry_fail += 1\n",
    "            else:\n",
    "                retry_fail += 1\n",
    "        except Exception as e:\n",
    "            retry_fail += 1\n",
    "    \n",
    "    print(f\"\\nRetry results: {retry_success} succeeded, {retry_fail} still failed\")\n",
    "    \n",
    "    # Show updated stats\n",
    "    stats = db.get_stats()\n",
    "    print(f\"ETFs with prices: {stats['etfs_with_prices']}/{stats['total_etfs']}\")\n",
    "else:\n",
    "    print(\"No ETFs need retry - all have price data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATABASE SUMMARY\n",
      "============================================================\n",
      "Total ETFs:          872\n",
      "ETFs with prices:    872\n",
      "Total price records: 2,063,930\n",
      "Price date range:    2005-11-18 to 2025-12-12\n",
      "Database size:       241.35 MB\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Database summary\n",
    "stats = db.get_stats()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATABASE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total ETFs:          {stats['total_etfs']}\")\n",
    "print(f\"ETFs with prices:    {stats['etfs_with_prices']}\")\n",
    "print(f\"Total price records: {stats['total_price_records']:,}\")\n",
    "if stats['price_date_range']:\n",
    "    print(f\"Price date range:    {stats['price_date_range'][0]} to {stats['price_date_range'][1]}\")\n",
    "print(f\"Database size:       {stats['db_size_mb']:.2f} MB\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Monthly Workflow\n",
    "\n",
    "**Each month, follow these steps:**\n",
    "\n",
    "1. **First**: Run the cell below to save a metadata snapshot (preserves current TER, fund_size values in history)\n",
    "2. **Then**: Re-run cells 1.1 through 1.4 to refresh everything\n",
    "\n",
    "**What happens when you re-run:**\n",
    "- ✅ New ETFs matching criteria are added to the database\n",
    "- ✅ Existing ETF metadata (TER, fund_size, months_of_data) is updated with latest values\n",
    "- ✅ All price data is refreshed (validated against existing data, then replaced)\n",
    "- ✅ The metadata snapshot preserves historical values for tracking changes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metadata snapshot for 872 ETFs\n"
     ]
    }
   ],
   "source": [
    "# Save metadata snapshot BEFORE re-running the fetch\n",
    "# This preserves current fund_size, TER values in history\n",
    "\n",
    "snapshot_count = db.save_metadata_snapshot()\n",
    "print(f\"Saved metadata snapshot for {snapshot_count} ETFs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata history: 872 records across 872 ETFs\n",
      "Snapshots: 1 dates\n",
      "Date range: 2025-12-15 to 2025-12-15\n"
     ]
    }
   ],
   "source": [
    "# View metadata history (tracks fund_size, TER changes over time)\n",
    "history = db.load_metadata_history()\n",
    "if len(history) > 0:\n",
    "    print(f\"Metadata history: {len(history)} records across {history['isin'].nunique()} ETFs\")\n",
    "    snapshots = history['snapshot_date'].nunique()\n",
    "    print(f\"Snapshots: {snapshots} dates\")\n",
    "    print(f\"Date range: {history['snapshot_date'].min().date()} to {history['snapshot_date'].max().date()}\")\n",
    "else:\n",
    "    print(\"No metadata history yet. Run the snapshot cell above before re-fetching.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Quick Data Access Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETF Universe: 872 ETFs\n",
      "           isin                                               name   ter  \\\n",
      "0  IE000K1P4V37  AMUNDI MSCI World SRI Climate Net Zero Ambitio...  0.20   \n",
      "1  IE0003A512E4  ARK Artificial Intelligence & Robotics UCITS E...  0.75   \n",
      "2  IE000O5M6XO1           ARK Genomic Revolution UCITS ETF USD Acc  0.75   \n",
      "3  IE000GA3D489               ARK Innovation UCITS ETF USD Acc ETF  0.75   \n",
      "4  IE000AON7ET1  ARK Space & Defence Innovation UCITS ETF (ARKX...  0.75   \n",
      "5  IE0003IT72N9  AXA IM ACT Biodiversity Equity UCITS ETF EUR H...  0.53   \n",
      "6  IE000SBHVL31   AXA IM ACT Biodiversity Equity UCITS ETF USD Acc  0.50   \n",
      "7  IE000Z8BHG02                AXA IM ACT Climate Equity UCITS ETF  0.50   \n",
      "8  IE000E66LX20    AXA IM ACT Climate Equity UCITS ETF EUR Hdg Acc  0.53   \n",
      "9  IE000GLIXPP3  AXA IM MSCI Emerging Markets Equity PAB UCITS ETF  0.24   \n",
      "\n",
      "   fund_size  \n",
      "0      350.0  \n",
      "1      301.0  \n",
      "2       40.0  \n",
      "3      309.0  \n",
      "4        2.0  \n",
      "5      116.0  \n",
      "6       13.0  \n",
      "7        7.0  \n",
      "8      132.0  \n",
      "9       17.0  \n"
     ]
    }
   ],
   "source": [
    "# Example: Load ETF universe\n",
    "universe = db.load_universe()\n",
    "print(f\"ETF Universe: {len(universe)} ETFs\")\n",
    "print(universe[['isin', 'name', 'ter', 'fund_size']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHAPTER 1 COMPLETE - ETF Data Collection\n",
      "============================================================\n",
      "\n",
      "Database: data/etf_database.db\n",
      "Total ETFs: 872\n",
      "ETFs with prices: 872\n",
      "Total price records: 2,063,930\n",
      "Database size: 241.44 MB\n",
      "\n",
      "Base filter criteria:\n",
      "  - Irish domicile (IE00)\n",
      "  - Accumulating distribution\n",
      "  - EUR currency\n",
      "  - No leveraged ETFs\n",
      "\n",
      "Monthly workflow:\n",
      "  1. Run Section 1.5 first (save metadata snapshot)\n",
      "  2. Re-run cells 1.1 through 1.4\n",
      "  3. Check Section 1.5 to view metadata history\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(\"=\"*60)\n",
    "print(\"CHAPTER 1 COMPLETE - ETF Data Collection\")\n",
    "print(\"=\"*60)\n",
    "stats = db.get_stats()\n",
    "print(f\"\\nDatabase: data/etf_database.db\")\n",
    "print(f\"Total ETFs: {stats['total_etfs']}\")\n",
    "print(f\"ETFs with prices: {stats['etfs_with_prices']}\")\n",
    "print(f\"Total price records: {stats['total_price_records']:,}\")\n",
    "print(f\"Database size: {stats['db_size_mb']:.2f} MB\")\n",
    "print(f\"\\nBase filter criteria:\")\n",
    "print(f\"  - Irish domicile (IE00)\")\n",
    "print(f\"  - Accumulating distribution\")\n",
    "print(f\"  - EUR currency\")\n",
    "print(f\"  - No leveraged ETFs\")\n",
    "print(f\"\\nMonthly workflow:\")\n",
    "print(f\"  1. Run Section 1.5 first (save metadata snapshot)\")\n",
    "print(f\"  2. Re-run cells 1.1 through 1.4\")\n",
    "print(f\"  3. Check Section 1.5 to view metadata history\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
